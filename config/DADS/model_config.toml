# Here you can define credentials for different data sets and environment.

# Here you can define training and inference configuration for training and inference pipeline.

# Example:
[Environment]
device = "cpu"
sample_num = 10  # number data sampled when sampling dataset_unlabeled,
# then choose the one with the highest unsupervised index (e.g. the one with the highest Iforest anomaly score)
max_trajectory = 5000  # number of steps per each episode
check_num = 100  # threshold of confidence
search_percentage = 0.5
reward_list = [1.0, -1.0, 1.0, 0.5]  # rewards used in calculating reward
sampling_method_distribution = [0.6, 0.4]  # probability distribution used to choose unsupervised method
anomaly_ratio = 0.2
score_threshold = 0.1
eval_interval = 500

[Agent]
min_steps_before_learning=10000
batch_size=64
update_every_n_steps=16
learning_updates_per_learning_session=16
add_extra_noise=false
discount_rate=0.99
num_episodes_to_run=10   # episodes per training
device="cpu"

automatically_tune_entropy_hyperparameter=true
entropy_term_weight="None"
mu=0.0
theta=0.1
sigma=0.1

[Agent.Actor]
learning_rate=0.0005
linear_hidden_units=[32, 32, 16]
final_layer_activation="Sigmoid"
batch_norm=false
tau=0.2
gradient_clipping_norm=5
initialiser="Xavier"

[Agent.Critic]
learning_rate=0.0005
linear_hidden_units=[32, 32, 16]
final_layer_activation="None"
batch_norm=false
buffer_size=100000
tau=0.2
gradient_clipping_norm=5
initialiser="Xavier"

[INFERENCE]
MODEL_DIR = "/models/dummy.p"
OUTPUT_DIR = "/data/output/inference.csv"
